{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparkSession' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bfd8eefa7e8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Predictor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'SparkSession' is not defined"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"Predictor\").getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-464191C:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Predictor</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1816721f588>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load(\"data/trends1.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+-----+-------------------+\n",
      "|Week|Top 1|Top 2|Top 3|               Date|\n",
      "+----+-----+-----+-----+-------------------+\n",
      "|   0|    4|   14|   14|2012-10-07 00:00:00|\n",
      "|   1|    7|   15|   18|2012-10-14 00:00:00|\n",
      "|   2|    5|   12|   15|2012-10-21 00:00:00|\n",
      "|   3|    5|   15|   12|2012-10-28 00:00:00|\n",
      "|   4|    4|   12|   12|2012-11-04 00:00:00|\n",
      "|   5|    4|   14|   10|2012-11-11 00:00:00|\n",
      "|   6|    4|   12|   12|2012-11-18 00:00:00|\n",
      "|   7|    7|   14|   15|2012-11-25 00:00:00|\n",
      "|   8|    4|   17|   15|2012-12-02 00:00:00|\n",
      "|   9|    3|   14|   10|2012-12-09 00:00:00|\n",
      "|  10|    5|    9|   11|2012-12-16 00:00:00|\n",
      "|  11|    7|   13|   11|2012-12-23 00:00:00|\n",
      "|  12|    6|   14|   14|2012-12-30 00:00:00|\n",
      "|  13|    4|   11|   11|2013-01-06 00:00:00|\n",
      "|  14|    4|   13|   16|2013-01-13 00:00:00|\n",
      "|  15|    5|   16|   15|2013-01-20 00:00:00|\n",
      "|  16|    4|   16|   13|2013-01-27 00:00:00|\n",
      "|  17|    4|   18|   14|2013-02-03 00:00:00|\n",
      "|  18|    5|   14|   15|2013-02-10 00:00:00|\n",
      "|  19|    3|   19|   15|2013-02-17 00:00:00|\n",
      "+----+-----+-----+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Week: integer (nullable = true)\n",
      " |-- Top 1: integer (nullable = true)\n",
      " |-- Top 2: integer (nullable = true)\n",
      " |-- Top 3: integer (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Week</th>\n",
       "      <td>261</td>\n",
       "      <td>130.0</td>\n",
       "      <td>75.48840970639135</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 1</th>\n",
       "      <td>261</td>\n",
       "      <td>11.796934865900383</td>\n",
       "      <td>8.474903572833036</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 2</th>\n",
       "      <td>261</td>\n",
       "      <td>36.23371647509578</td>\n",
       "      <td>26.61901744235176</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3</th>\n",
       "      <td>261</td>\n",
       "      <td>23.452107279693486</td>\n",
       "      <td>8.180335553818198</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                   1                  2    3    4\n",
       "summary  count                mean             stddev  min  max\n",
       "Week       261               130.0  75.48840970639135    0  260\n",
       "Top 1      261  11.796934865900383  8.474903572833036    3   29\n",
       "Top 2      261   36.23371647509578  26.61901744235176    9  100\n",
       "Top 3      261  23.452107279693486  8.180335553818198   10   43"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['Week'], outputCol = 'vWeek')\n",
    "vdf = vectorAssembler.transform(df)\n",
    "\n",
    "splits = vdf.randomSplit([0.8, 0.2])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "\n",
    "T1_train = train_df.select([\"vWeek\",\"Top 1\"])\n",
    "T2_train = train_df.select([\"vWeek\",\"Top 2\"])\n",
    "T3_train = train_df.select([\"vWeek\",\"Top 3\"])\n",
    "\n",
    "T1_test = test_df.select([\"vWeek\",\"Top 1\"])\n",
    "T2_test = test_df.select([\"vWeek\",\"Top 2\"])\n",
    "T3_test = test_df.select([\"vWeek\",\"Top 3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| vWeek|Top 1|\n",
      "+------+-----+\n",
      "| [0.0]|    4|\n",
      "| [1.0]|    7|\n",
      "| [2.0]|    5|\n",
      "| [3.0]|    5|\n",
      "| [4.0]|    4|\n",
      "| [5.0]|    4|\n",
      "| [6.0]|    4|\n",
      "| [7.0]|    7|\n",
      "| [8.0]|    4|\n",
      "|[10.0]|    5|\n",
      "|[11.0]|    7|\n",
      "|[12.0]|    6|\n",
      "|[13.0]|    4|\n",
      "|[14.0]|    4|\n",
      "|[16.0]|    4|\n",
      "|[17.0]|    4|\n",
      "|[18.0]|    5|\n",
      "|[20.0]|    3|\n",
      "|[21.0]|    6|\n",
      "|[22.0]|    4|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T1_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1\n",
      "Coefficients: [0.08845919368512574]\n",
      "Intercept: 0.24514936196353063\n",
      "Top 2\n",
      "Coefficients: [0.29202621260780054]\n",
      "Intercept: -1.546093674699278\n",
      "Top 3\n",
      "Coefficients: [0.08675699530450738]\n",
      "Intercept: 12.352132803078526\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr1 = LinearRegression(featuresCol = 'vWeek', labelCol='Top 1', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr2 = LinearRegression(featuresCol = 'vWeek', labelCol='Top 2', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr3 = LinearRegression(featuresCol = 'vWeek', labelCol='Top 3', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "lr_model1 = lr1.fit(T1_train)\n",
    "lr_model2 = lr2.fit(T2_train)\n",
    "lr_model3 = lr3.fit(T3_train)\n",
    "\n",
    "print(\"Top 1\") \n",
    "print(\"Coefficients: \" + str(lr_model1.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model1.intercept))\n",
    "\n",
    "print(\"Top 2\") \n",
    "print(\"Coefficients: \" + str(lr_model2.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model2.intercept))\n",
    "\n",
    "print(\"Top 3\") \n",
    "print(\"Coefficients: \" + str(lr_model3.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model3.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1\n",
      "RMSE: 4.763272\n",
      "r2: 0.685691\n",
      "Top 2\n",
      "RMSE: 14.712575\n",
      "r2: 0.702035\n",
      "Top 3\n",
      "RMSE: 4.419135\n",
      "r2: 0.709494\n"
     ]
    }
   ],
   "source": [
    "trainingSummary1 = lr_model1.summary\n",
    "trainingSummary2 = lr_model2.summary\n",
    "trainingSummary3 = lr_model3.summary\n",
    "\n",
    "print(\"Top 1\")\n",
    "print(\"RMSE: %f\" % trainingSummary1.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary1.r2)\n",
    "\n",
    "print(\"Top 2\")\n",
    "print(\"RMSE: %f\" % trainingSummary2.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary2.r2)\n",
    "\n",
    "print(\"Top 3\")\n",
    "print(\"RMSE: %f\" % trainingSummary3.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary3.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-----------------+\n",
      "|summary|              Week|             Top 1|             Top 2|            Top 3|\n",
      "+-------+------------------+------------------+------------------+-----------------+\n",
      "|  count|               203|               203|               203|              203|\n",
      "|   mean|129.64039408866995|11.665024630541872| 35.70935960591133|23.48768472906404|\n",
      "| stddev| 75.58657578861401|  8.47688227144537|26.382548632763704|8.273995769827428|\n",
      "|    min|                 0|                 3|                 9|               10|\n",
      "|    max|               260|                29|               100|               43|\n",
      "+-------+------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1\n",
      "+------------------+-----+-------+\n",
      "|        prediction|Top 1|  vWeek|\n",
      "+------------------+-----+-------+\n",
      "|0.3360659198983003|    5|  [3.0]|\n",
      "|0.5149813250842847|    4|  [5.0]|\n",
      "|0.6044390276772771|    4|  [6.0]|\n",
      "|0.6938967302702694|    7|  [7.0]|\n",
      "| 1.588473756200192|    4| [17.0]|\n",
      "|1.6779314587931842|    5| [18.0]|\n",
      "|2.1252199717581455|    5| [23.0]|\n",
      "|2.4830507821301144|    4| [27.0]|\n",
      "| 2.840881592502084|    4| [31.0]|\n",
      "|3.3776278080600375|    4| [37.0]|\n",
      "| 3.646000915839014|    3| [40.0]|\n",
      "|3.9143740236179907|    4| [43.0]|\n",
      "| 4.898408752140906|    6| [54.0]|\n",
      "| 5.256239562512875|    6| [58.0]|\n",
      "| 6.508647398814767|    4| [72.0]|\n",
      "| 6.777020506593744|    5| [75.0]|\n",
      "| 6.955935911779728|    3| [77.0]|\n",
      "|  8.20834374808162|    4| [91.0]|\n",
      "| 8.745089963639574|    5| [97.0]|\n",
      "| 9.102920774011542|    6|[101.0]|\n",
      "+------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "--------------------------------------------------------------\n",
      "R Squared (R2) on test data = 0.69006\n",
      "Root Mean Squared Error (RMSE) on test data = 4.70531\n",
      "--------------------------------------------------------------\n",
      "numIterations: 3\n",
      "objectiveHistory: [0.5000000000000002, 0.42370740086316444, 0.17959948028170927]\n",
      "+------------------+\n",
      "|         residuals|\n",
      "+------------------+\n",
      "|3.9323071878806766|\n",
      "| 6.842849485287684|\n",
      "| 4.753391782694692|\n",
      "|3.5744763775087076|\n",
      "| 3.216645567136738|\n",
      "| 2.127187864543746|\n",
      "| 4.037730161950754|\n",
      "| 5.948272459357762|\n",
      "| 4.858814756764769|\n",
      "| 2.769357054171777|\n",
      "|2.6798993515787846|\n",
      "|3.5904416489857924|\n",
      "|2.5009839463928003|\n",
      "|1.2326108386138235|\n",
      "|1.1431531360208314|\n",
      "| 4.053695433427839|\n",
      "|1.9642377308348467|\n",
      "| 0.785322325648862|\n",
      "|  2.69586462305587|\n",
      "|2.6064069204628777|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 1\")\n",
    "lr_predictions1 = lr_model1.transform(T1_test)\n",
    "lr_predictions1.select(\"prediction\",\"Top 1\",\"vWeek\").show()\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator1 = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"Top 1\",metricName=\"r2\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator1.evaluate(lr_predictions1))\n",
    "\n",
    "test_result1 = lr_model1.evaluate(T1_test)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result1.rootMeanSquaredError)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"numIterations: %d\" % trainingSummary1.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary1.objectiveHistory))\n",
    "trainingSummary1.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2\n",
      "+------------------+-----+------+\n",
      "|        prediction|Top 2| vWeek|\n",
      "+------------------+-----+------+\n",
      "| 1.082142238770927|   14| [9.0]|\n",
      "|2.8342995144177303|   16|[15.0]|\n",
      "| 4.002404364848933|   19|[19.0]|\n",
      "| 5.170509215280135|   16|[23.0]|\n",
      "| 7.214692703534738|   19|[30.0]|\n",
      "|  7.50671891614254|   15|[31.0]|\n",
      "|  8.67482376657374|   16|[35.0]|\n",
      "|  9.25887619178934|   20|[37.0]|\n",
      "|11.595085892651745|   17|[45.0]|\n",
      "|11.887112105259547|   18|[46.0]|\n",
      "|12.471164530475146|   18|[48.0]|\n",
      "|15.391426656553154|   14|[58.0]|\n",
      "|16.559531506984356|   14|[62.0]|\n",
      "|17.143583932199956|   14|[64.0]|\n",
      "| 18.60371499523896|   16|[69.0]|\n",
      "| 19.47979363306236|   20|[72.0]|\n",
      "|19.771819845670162|   20|[73.0]|\n",
      "| 20.35587227088576|   19|[75.0]|\n",
      "|20.647898483493563|   22|[76.0]|\n",
      "|21.231950908709162|   19|[78.0]|\n",
      "+------------------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "--------------------------------------------------------------\n",
      "R Squared (R2) on test data = 0.580162\n",
      "Root Mean Squared Error (RMSE) on test data = 15.4044\n",
      "--------------------------------------------------------------\n",
      "numIterations: 3\n",
      "objectiveHistory: [0.5000000000000001, 0.41928381444914564, 0.1571097240831175]\n",
      "+------------------+\n",
      "|         residuals|\n",
      "+------------------+\n",
      "|15.546093674699279|\n",
      "|16.254067462091477|\n",
      "|12.962041249483677|\n",
      "|15.670015036875876|\n",
      "|12.377988824268076|\n",
      "|14.085962611660275|\n",
      "|11.793936399052475|\n",
      "|13.501910186444674|\n",
      "|16.209883973836874|\n",
      "| 7.625831548621273|\n",
      "|11.333805336013471|\n",
      "|12.041779123405671|\n",
      "|  8.74975291079787|\n",
      "| 10.45772669819007|\n",
      "|12.873674272974469|\n",
      "|14.581648060366668|\n",
      "|10.289621847758868|\n",
      "|14.705569422543267|\n",
      "|13.413543209935465|\n",
      "|15.121516997327666|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 2\")\n",
    "lr_predictions2 = lr_model2.transform(T2_test)\n",
    "lr_predictions2.select(\"prediction\",\"Top 2\",\"vWeek\").show()\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator2 = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"Top 2\",metricName=\"r2\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator2.evaluate(lr_predictions2))\n",
    "\n",
    "test_result2 = lr_model2.evaluate(T2_test)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result2.rootMeanSquaredError)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"numIterations: %d\" % trainingSummary2.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary2.objectiveHistory))\n",
    "trainingSummary2.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3\n",
      "+------------------+-----+-------+\n",
      "|        prediction|Top 3|  vWeek|\n",
      "+------------------+-----+-------+\n",
      "|12.141067889102008|   12|  [3.0]|\n",
      "|12.320262164698109|   10|  [5.0]|\n",
      "| 12.40985930249616|   12|  [6.0]|\n",
      "| 12.49945644029421|   15|  [7.0]|\n",
      "| 13.39542781827472|   14| [17.0]|\n",
      "| 13.48502495607277|   15| [18.0]|\n",
      "|13.933010645063025|   15| [23.0]|\n",
      "| 14.29139919625523|   18| [27.0]|\n",
      "|14.649787747447434|   14| [31.0]|\n",
      "| 15.18737057423574|   13| [37.0]|\n",
      "| 15.45616198762989|   14| [40.0]|\n",
      "|15.724953401024043|   14| [43.0]|\n",
      "|16.710521916802605|   16| [54.0]|\n",
      "|17.068910467994808|   17| [58.0]|\n",
      "| 18.32327039716752|   16| [72.0]|\n",
      "|18.592061810561674|   16| [75.0]|\n",
      "|18.771256086157774|   23| [77.0]|\n",
      "| 20.02561601533049|   25| [91.0]|\n",
      "|20.563198842118794|   21| [97.0]|\n",
      "|20.921587393310997|   17|[101.0]|\n",
      "+------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "--------------------------------------------------------------\n",
      "R Squared (R2) on test data = 0.696685\n",
      "Root Mean Squared Error (RMSE) on test data = 4.32009\n",
      "--------------------------------------------------------------\n",
      "numIterations: 3\n",
      "objectiveHistory: [0.5000000000000009, 0.421561661207089, 0.16258627728765013]\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|  2.1277235242921453|\n",
      "|   6.038126386494094|\n",
      "|   2.948529248696044|\n",
      "| -0.2306650269000592|\n",
      "|   2.410946421907738|\n",
      "| -2.6786507158903134|\n",
      "| -1.7682478536883632|\n",
      "| -1.8578449914864148|\n",
      "|  1.0525578707155336|\n",
      "|  -2.037039267082516|\n",
      "|  2.8733635951194323|\n",
      "|  1.7837664573213807|\n",
      "|-0.30583068047666906|\n",
      "|   1.425377906129178|\n",
      "| -0.6642192316688735|\n",
      "| -0.7538163694669233|\n",
      "|   2.156586492735025|\n",
      "|  1.9773922171389238|\n",
      "|   3.887795079340872|\n",
      "|  0.7981979415428206|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 3\")\n",
    "lr_predictions3 = lr_model3.transform(T3_test)\n",
    "lr_predictions3.select(\"prediction\",\"Top 3\",\"vWeek\").show()\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator3 = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"Top 3\",metricName=\"r2\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator3.evaluate(lr_predictions3))\n",
    "\n",
    "test_result3 = lr_model3.evaluate(T3_test)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result3.rootMeanSquaredError)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"numIterations: %d\" % trainingSummary3.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary3.objectiveHistory))\n",
    "trainingSummary3.residuals.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
